{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d",
      "metadata": {},
      "source": [
        "# Internet Search using Bing API - Bing Chat Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f",
      "metadata": {},
      "source": [
        "In this notebook, we'll delve into a sample for REACT framework for bing search agent in  **Bing Search Engine Agent**, utilizing both Langchain and the Azure Bing Search API service **harnessing agents and tools**, leveraging the capabilities of OpenAI's large language models (LLM), to perform the heavy lifting of reasoning and researching on our behalf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c1fb79a3-4856-4721-988c-112813690a90",
      "metadata": {
        "gather": {
          "logged": 1696222294579
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel, Extra, root_validator\n",
        "\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.utilities import BingSearchAPIWrapper\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BING_PROMPT_PREFIX\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "# GPT-4 models are necessary for this feature. GPT-35-turbo will make mistakes multiple times on following system prompt instructions.\n",
        "MODEL_DEPLOYMENT_NAME = \"gpt-35-turbo-16k\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "258a6e99-2d4f-4147-b8ee-c64c85296181",
      "metadata": {
        "gather": {
          "logged": 1696222294755
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"OPENAI_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa",
      "metadata": {},
      "source": [
        "## Introduction to Callback Handlers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "003327ac-2851-48ef-8a6b-2d8c2004bb2e",
      "metadata": {},
      "source": [
        "This following explanation comes directly from the Langchain documentation about Callbacks ([HERE](https://python.langchain.com/docs/modules/callbacks/)):\n",
        "\n",
        "**Callbacks**:<br>\n",
        "LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks. You can subscribe to these events by using the callbacks argument available throughout the API. This argument is list of handler objects.\n",
        "\n",
        "**Callback handlers**:<br>\n",
        "CallbackHandlers are objects that implement the CallbackHandler interface, which has a method for each event that can be subscribed to. The CallbackManager will call the appropriate method on each handler when the event is triggered.\n",
        "\n",
        "--------------------\n",
        "We will incorporate a handler for the callbacks, enabling us to observe the response as it streams and to gain insights into the Agent's reasoning process. This will prove incredibly valuable when we aim to stream the bot's responses to users and keep them informed about the ongoing process as they await the answer.\n",
        "\n",
        "Our custom handler is on the folder `common/callbacks.py`. Go and take a look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9d3daf03-77e2-466e-a255-2f06bee3561b",
      "metadata": {
        "gather": {
          "logged": 1696222294936
        }
      },
      "outputs": [],
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "# Now we declare our LLM object with the callback handler \n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0, max_tokens=1000)\n",
        "\n",
        "# or uncomment the below line if you want to see the responses being streamed\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0, max_tokens=1000, streaming=True, callback_manager=cb_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11da70c2-60b6-47fb-94f1-aa11291fa40c",
      "metadata": {},
      "source": [
        "## Creating a custom tool - Bing Search API tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc30c9d-605d-4ada-9358-f926aeed2e48",
      "metadata": {},
      "source": [
        "Langhain has already a pre-created tool called BingSearchAPIWrapper ([HERE](https://github.com/hwchase17/langchain/blob/master/langchain/utilities/bing_search.py)), however we are going to make it a bit better by using the results function instead of the run function, that way we not only have the text results, but also the title and link(source) of each snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d3d155ae-16eb-458a-b2ed-5aa9a9b84ed8",
      "metadata": {
        "gather": {
          "logged": 1696222295118
        }
      },
      "outputs": [],
      "source": [
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
        "    \n",
        "    name = \"@bing\"\n",
        "    description = \"useful when the questions includes the term: @bing.\\n\"\n",
        "\n",
        "    k: int = 5\n",
        "    \n",
        "    def _run(self, query: str) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query,num_results=self.k)\n",
        "            \n",
        "    async def _arun(self, query: str) -> str:\n",
        "        \"\"\"Use the tool asynchronously.\"\"\"\n",
        "        raise NotImplementedError(\"This Tool does not support async\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3d6569-0c61-4b1c-9263-431304577551",
      "metadata": {},
      "source": [
        "Now, we create our REACT agent that uses our custom tool and our custom prompt `BING_PROMPT_PREFIX`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2c6cf721-76bb-47b6-aeeb-9ff4ff92b1f4",
      "metadata": {
        "gather": {
          "logged": 1696222295287
        }
      },
      "outputs": [],
      "source": [
        "tools = [MyBingSearch(k=5)]\n",
        "agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
        "                         agent_kwargs={'prefix':BING_PROMPT_PREFIX}, callback_manager=cb_manager, )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7232260e-e972-4288-b0b5-0b605e584528",
      "metadata": {},
      "source": [
        "Try some of the below questions, or others that you might like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a448f8-6363-4229-8f52-7e75ea80069c",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#QUESTION = \"can I travel to Hawaii, Maui from Dallas, TX for 7 days with $7000 on the month of September, what are the best days to travel?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fa949cea-c9aa-4529-a75f-61084ffffd7e",
      "metadata": {
        "gather": {
          "logged": 1696222751321
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "QUESTION = \"What is Emma Watson's age add 50?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ca910f71-60fb-4758-b4a9-757e37eb421f",
      "metadata": {
        "gather": {
          "logged": 1696222763972
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I need to find Emma Watson's age and add 50 to it.\n",
            "Action: @bing\n",
            "Action Input: \"Emma Watson age\"I need to find Emma Watson's age and add 50 to it.\n",
            "Action: @bing\n",
            "Action Input: \"Emma Watson age\"\n",
            "I have found multiple sources that provide Emma Watson's age. According to these sources, Emma Watson was born on April 15, 1990. To calculate her age, we can subtract her birth year from the current year. Let's do the math: \n",
            "\n",
            "Current year: 2022\n",
            "Emma Watson's birth year: 1990\n",
            "\n",
            "2022 - 1990 = 32\n",
            "\n",
            "Emma Watson is currently 32 years old. \n",
            "\n",
            "To add 50 to her age, we can simply add 50 to the result:\n",
            "\n",
            "32 + 50 = 82\n",
            "\n",
            "So, if we add 50 to Emma Watson's age, the result is 82.I need to find Emma Watson's age and add 50 to it.\n",
            "Action: @bing\n",
            "Action Input: \"Emma Watson age\"I need to find Emma Watson's age and add 50 to it.\n",
            "Action: @bing\n",
            "Action Input: \"Emma Watson age\"\n",
            "I have found multiple sources that provide Emma Watson's age. According to these sources, Emma Watson was born on April 15, 1990. To calculate her age, we can subtract her birth year from the current year. Let's do the math: \n",
            "\n",
            "Current year: 2022\n",
            "Emma Watson's birth year: 1990\n",
            "\n",
            "2022 - 1990 = 32\n",
            "\n",
            "Emma Watson is currently 32 years old. \n",
            "\n",
            "To add 50 to her age, we can simply add 50 to the result:\n",
            "\n",
            "32 + 50 = 82\n",
            "\n",
            "So, if we add 50 to Emma Watson's age, the result is 82."
          ]
        }
      ],
      "source": [
        "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
